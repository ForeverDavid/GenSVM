<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - coverage.all - src/gensvm_optimize.c</title>
  <link rel="stylesheet" type="text/css" href="../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../index.html">top level</a> - <a href="index.html">src</a> - gensvm_optimize.c<span style="font-size: 80%;"> (source / <a href="gensvm_optimize.c.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">coverage.all</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">98</td>
            <td class="headerCovTableEntry">100</td>
            <td class="headerCovTableEntryHi">98.0 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2017-01-02 10:11:09</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">5</td>
            <td class="headerCovTableEntry">5</td>
            <td class="headerCovTableEntryHi">100.0 %</td>
          </tr>
          <tr><td><img src="../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : /**</a>
<span class="lineNum">       2 </span>            :  * @file gensvm_optimize.c
<span class="lineNum">       3 </span>            :  * @author G.J.J. van den Burg
<span class="lineNum">       4 </span>            :  * @date 2013-08-09
<span class="lineNum">       5 </span>            :  * @brief Main functions for training the GenSVM solution.
<span class="lineNum">       6 </span>            :  *
<span class="lineNum">       7 </span>            :  * @details
<span class="lineNum">       8 </span>            :  * Contains update and loss functions used to actually find
<span class="lineNum">       9 </span>            :  * the optimal V.
<span class="lineNum">      10 </span>            :  *
<span class="lineNum">      11 </span>            :  * @copyright
<span class="lineNum">      12 </span>            :  Copyright 2016, G.J.J. van den Burg.
<span class="lineNum">      13 </span>            : 
<span class="lineNum">      14 </span>            :  This file is part of GenSVM.
<span class="lineNum">      15 </span>            : 
<span class="lineNum">      16 </span>            :  GenSVM is free software: you can redistribute it and/or modify
<span class="lineNum">      17 </span>            :  it under the terms of the GNU General Public License as published by
<span class="lineNum">      18 </span>            :  the Free Software Foundation, either version 3 of the License, or
<span class="lineNum">      19 </span>            :  (at your option) any later version.
<span class="lineNum">      20 </span>            : 
<span class="lineNum">      21 </span>            :  GenSVM is distributed in the hope that it will be useful,
<span class="lineNum">      22 </span>            :  but WITHOUT ANY WARRANTY; without even the implied warranty of
<span class="lineNum">      23 </span>            :  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
<span class="lineNum">      24 </span>            :  GNU General Public License for more details.
<span class="lineNum">      25 </span>            : 
<span class="lineNum">      26 </span>            :  You should have received a copy of the GNU General Public License
<span class="lineNum">      27 </span>            :  along with GenSVM. If not, see &lt;http://www.gnu.org/licenses/&gt;.
<span class="lineNum">      28 </span>            : 
<span class="lineNum">      29 </span>            :  */
<span class="lineNum">      30 </span>            : 
<span class="lineNum">      31 </span>            : #include &quot;gensvm_optimize.h&quot;
<span class="lineNum">      32 </span>            : 
<span class="lineNum">      33 </span>            : /**
<span class="lineNum">      34 </span>            :  * Maximum number of iterations of the algorithm.
<span class="lineNum">      35 </span>            :  */
<span class="lineNum">      36 </span>            : #ifndef GENSVM_MAX_ITER
<span class="lineNum">      37 </span>            :   #define GENSVM_MAX_ITER 1000000000
<span class="lineNum">      38 </span>            : #endif
<span class="lineNum">      39 </span>            : 
<span class="lineNum">      40 </span>            : /**
<span class="lineNum">      41 </span>            :  * Iteration frequency with which to print to stdout
<span class="lineNum">      42 </span>            :  */
<span class="lineNum">      43 </span>            : #ifndef GENSVM_PRINT_ITER
<span class="lineNum">      44 </span>            :   #define GENSVM_PRINT_ITER 100
<span class="lineNum">      45 </span>            : #endif
<span class="lineNum">      46 </span>            : 
<span class="lineNum">      47 </span>            : /**
<span class="lineNum">      48 </span>            :  * @brief The main training loop for GenSVM
<span class="lineNum">      49 </span>            :  *
<span class="lineNum">      50 </span>            :  * @details
<span class="lineNum">      51 </span>            :  * This function is the main training function. This function
<span class="lineNum">      52 </span>            :  * handles the optimization of the model with the given model parameters, with
<span class="lineNum">      53 </span>            :  * the data given. On return the matrix GenModel::V contains the optimal
<span class="lineNum">      54 </span>            :  * weight matrix.
<span class="lineNum">      55 </span>            :  *
<span class="lineNum">      56 </span>            :  * In this function, step doubling is used in the majorization algorithm after
<span class="lineNum">      57 </span>            :  * a burn-in of 50 iterations.
<span class="lineNum">      58 </span>            :  *
<span class="lineNum">      59 </span>            :  * @param[in,out]       model   the GenModel to be trained. Contains optimal
<span class="lineNum">      60 </span>            :  *                              V on exit.
<a name="61"><span class="lineNum">      61 </span>            :  * @param[in]           data    the GenData to train the model with.</a>
<span class="lineNum">      62 </span>            :  */
<span class="lineNum">      63 </span><span class="lineCov">          3 : void gensvm_optimize(struct GenModel *model, struct GenData *data)</span>
<span class="lineNum">      64 </span>            : {
<span class="lineNum">      65 </span><span class="lineCov">          3 :         long it = 0;</span>
<span class="lineNum">      66 </span>            :         double L, Lbar;
<span class="lineNum">      67 </span>            : 
<span class="lineNum">      68 </span><span class="lineCov">          3 :         long n = model-&gt;n;</span>
<span class="lineNum">      69 </span><span class="lineCov">          3 :         long m = model-&gt;m;</span>
<span class="lineNum">      70 </span><span class="lineCov">          3 :         long K = model-&gt;K;</span>
<span class="lineNum">      71 </span>            : 
<span class="lineNum">      72 </span>            :         // initialize the workspace
<span class="lineNum">      73 </span><span class="lineCov">          3 :         struct GenWork *work = gensvm_init_work(model);</span>
<span class="lineNum">      74 </span>            : 
<span class="lineNum">      75 </span>            :         // print some info on the dataset and model configuration
<span class="lineNum">      76 </span><span class="lineCov">          3 :         note(&quot;Starting main loop.\n&quot;);</span>
<span class="lineNum">      77 </span><span class="lineCov">          3 :         note(&quot;Dataset:\n&quot;);</span>
<span class="lineNum">      78 </span><span class="lineCov">          3 :         note(&quot;\tn = %i\n&quot;, n);</span>
<span class="lineNum">      79 </span><span class="lineCov">          3 :         note(&quot;\tm = %i\n&quot;, m);</span>
<span class="lineNum">      80 </span><span class="lineCov">          3 :         note(&quot;\tK = %i\n&quot;, K);</span>
<span class="lineNum">      81 </span><span class="lineCov">          3 :         note(&quot;Parameters:\n&quot;);</span>
<span class="lineNum">      82 </span><span class="lineCov">          3 :         note(&quot;\tkappa = %f\n&quot;, model-&gt;kappa);</span>
<span class="lineNum">      83 </span><span class="lineCov">          3 :         note(&quot;\tp = %f\n&quot;, model-&gt;p);</span>
<span class="lineNum">      84 </span><span class="lineCov">          3 :         note(&quot;\tlambda = %15.16f\n&quot;, model-&gt;lambda);</span>
<span class="lineNum">      85 </span><span class="lineCov">          3 :         note(&quot;\tepsilon = %g\n&quot;, model-&gt;epsilon);</span>
<span class="lineNum">      86 </span><span class="lineCov">          3 :         note(&quot;\n&quot;);</span>
<span class="lineNum">      87 </span>            : 
<span class="lineNum">      88 </span>            :         // compute necessary simplex vectors
<span class="lineNum">      89 </span><span class="lineCov">          3 :         gensvm_simplex(model);</span>
<span class="lineNum">      90 </span><span class="lineCov">          3 :         gensvm_simplex_diff(model);</span>
<span class="lineNum">      91 </span>            : 
<span class="lineNum">      92 </span>            :         // get initial loss
<span class="lineNum">      93 </span><span class="lineCov">          3 :         L = gensvm_get_loss(model, data, work);</span>
<span class="lineNum">      94 </span><span class="lineCov">          3 :         Lbar = L + 2.0*model-&gt;epsilon*L;</span>
<span class="lineNum">      95 </span>            : 
<span class="lineNum">      96 </span>            :         // run main loop
<span class="lineNum">      97 </span><span class="lineCov">        470 :         while ((it &lt; GENSVM_MAX_ITER) &amp;&amp; (Lbar - L)/L &gt; model-&gt;epsilon)</span>
<span class="lineNum">      98 </span>            :         {
<span class="lineNum">      99 </span>            :                 // ensures V contains newest V and Vbar contains V from
<span class="lineNum">     100 </span>            :                 // previous
<span class="lineNum">     101 </span><span class="lineCov">        464 :                 gensvm_get_update(model, data, work);</span>
<span class="lineNum">     102 </span><span class="lineCov">        464 :                 if (it &gt; 50)</span>
<span class="lineNum">     103 </span><span class="lineCov">        311 :                         gensvm_step_doubling(model);</span>
<span class="lineNum">     104 </span>            : 
<span class="lineNum">     105 </span><span class="lineCov">        464 :                 Lbar = L;</span>
<span class="lineNum">     106 </span><span class="lineCov">        464 :                 L = gensvm_get_loss(model, data, work);</span>
<span class="lineNum">     107 </span>            : 
<span class="lineNum">     108 </span><span class="lineCov">        464 :                 if (it % GENSVM_PRINT_ITER == 0)</span>
<span class="lineNum">     109 </span><span class="lineCov">          6 :                         note(&quot;iter = %li, L = %15.16f, Lbar = %15.16f, &quot;</span>
<span class="lineNum">     110 </span><span class="lineCov">          6 :                              &quot;reldiff = %15.16f\n&quot;, it, L, Lbar, (Lbar - L)/L);</span>
<span class="lineNum">     111 </span><span class="lineCov">        464 :                 it++;</span>
<span class="lineNum">     112 </span>            :         }
<span class="lineNum">     113 </span>            : 
<span class="lineNum">     114 </span>            :         // print warnings if necessary
<span class="lineNum">     115 </span><span class="lineCov">          3 :         if (L &gt; Lbar)</span>
<span class="lineNum">     116 </span><span class="lineNoCov">          0 :                 err(&quot;[GenSVM Warning]: Negative step occurred in &quot;</span>
<span class="lineNum">     117 </span>            :                                 &quot;majorization.\n&quot;);
<span class="lineNum">     118 </span><span class="lineCov">          3 :         if (it &gt;= GENSVM_MAX_ITER)</span>
<span class="lineNum">     119 </span><span class="lineNoCov">          0 :                 err(&quot;[GenSVM Warning]: maximum number of iterations &quot;</span>
<span class="lineNum">     120 </span>            :                                 &quot;reached.\n&quot;);
<span class="lineNum">     121 </span>            : 
<span class="lineNum">     122 </span>            :         // print final iteration count and loss
<span class="lineNum">     123 </span><span class="lineCov">          3 :         note(&quot;Optimization finished, iter = %li, loss = %15.16f, &quot;</span>
<span class="lineNum">     124 </span>            :                         &quot;rel. diff. = %15.16f\n&quot;, it-1, L,
<span class="lineNum">     125 </span><span class="lineCov">          3 :                         (Lbar - L)/L);</span>
<span class="lineNum">     126 </span>            : 
<span class="lineNum">     127 </span>            :         // compute and print the number of SVs in the model
<span class="lineNum">     128 </span><span class="lineCov">          3 :         note(&quot;Number of support vectors: %li\n&quot;, gensvm_num_sv(model));</span>
<span class="lineNum">     129 </span>            : 
<span class="lineNum">     130 </span>            :         // store the training error in the model
<span class="lineNum">     131 </span><span class="lineCov">          3 :         model-&gt;training_error = (Lbar - L)/L;</span>
<span class="lineNum">     132 </span>            : 
<span class="lineNum">     133 </span>            :         // free the workspace
<span class="lineNum">     134 </span><span class="lineCov">          3 :         gensvm_free_work(work);</span>
<span class="lineNum">     135 </span><span class="lineCov">          3 : }</span>
<span class="lineNum">     136 </span>            : 
<span class="lineNum">     137 </span>            : /**
<span class="lineNum">     138 </span>            :  * @brief Calculate the current value of the loss function
<span class="lineNum">     139 </span>            :  *
<span class="lineNum">     140 </span>            :  * @details
<span class="lineNum">     141 </span>            :  * The current loss function value is calculated based on the matrix V in the
<span class="lineNum">     142 </span>            :  * given model. Note that the matrix ZV is passed explicitly to avoid having
<span class="lineNum">     143 </span>            :  * to reallocate memory at every step.
<span class="lineNum">     144 </span>            :  *
<span class="lineNum">     145 </span>            :  * @param[in]           model   GenModel structure which holds the current
<span class="lineNum">     146 </span>            :  *                              estimate V
<span class="lineNum">     147 </span>            :  * @param[in]           data    GenData structure
<span class="lineNum">     148 </span>            :  * @param[in]           work    allocated workspace with the ZV matrix to use
<a name="149"><span class="lineNum">     149 </span>            :  * @returns                     the current value of the loss function</a>
<span class="lineNum">     150 </span>            :  */
<span class="lineNum">     151 </span><span class="lineCov">        469 : double gensvm_get_loss(struct GenModel *model, struct GenData *data, </span>
<span class="lineNum">     152 </span>            :                 struct GenWork *work)
<span class="lineNum">     153 </span>            : {
<span class="lineNum">     154 </span>            :         long i, j;
<span class="lineNum">     155 </span><span class="lineCov">        469 :         long n = model-&gt;n;</span>
<span class="lineNum">     156 </span><span class="lineCov">        469 :         long K = model-&gt;K;</span>
<span class="lineNum">     157 </span><span class="lineCov">        469 :         long m = model-&gt;m;</span>
<span class="lineNum">     158 </span>            : 
<span class="lineNum">     159 </span><span class="lineCov">        469 :         double value, rowvalue, loss = 0.0;</span>
<span class="lineNum">     160 </span>            : 
<span class="lineNum">     161 </span><span class="lineCov">        469 :         gensvm_calculate_errors(model, data, work-&gt;ZV);</span>
<span class="lineNum">     162 </span><span class="lineCov">        469 :         gensvm_calculate_huber(model);</span>
<span class="lineNum">     163 </span>            : 
<span class="lineNum">     164 </span><span class="lineCov">       4889 :         for (i=0; i&lt;n; i++) {</span>
<span class="lineNum">     165 </span><span class="lineCov">       4420 :                 rowvalue = 0;</span>
<span class="lineNum">     166 </span><span class="lineCov">       4420 :                 value = 0;</span>
<span class="lineNum">     167 </span><span class="lineCov">      22084 :                 for (j=0; j&lt;K; j++) {</span>
<span class="lineNum">     168 </span><span class="lineCov">      17664 :                         if (j == (data-&gt;y[i]-1))</span>
<span class="lineNum">     169 </span><span class="lineCov">       4420 :                                 continue;</span>
<span class="lineNum">     170 </span><span class="lineCov">      13244 :                         value = matrix_get(model-&gt;H, K, i, j);</span>
<span class="lineNum">     171 </span><span class="lineCov">      13244 :                         value = pow(value, model-&gt;p);</span>
<span class="lineNum">     172 </span><span class="lineCov">      13244 :                         rowvalue += value;</span>
<span class="lineNum">     173 </span>            :                 }
<span class="lineNum">     174 </span><span class="lineCov">       4420 :                 rowvalue = pow(rowvalue, 1.0/(model-&gt;p));</span>
<span class="lineNum">     175 </span><span class="lineCov">       4420 :                 rowvalue *= model-&gt;rho[i];</span>
<span class="lineNum">     176 </span><span class="lineCov">       4420 :                 loss += rowvalue;</span>
<span class="lineNum">     177 </span>            :         }
<span class="lineNum">     178 </span><span class="lineCov">        469 :         loss /= ((double) n);</span>
<span class="lineNum">     179 </span>            : 
<span class="lineNum">     180 </span><span class="lineCov">        469 :         value = 0;</span>
<span class="lineNum">     181 </span><span class="lineCov">       2314 :         for (i=1; i&lt;m+1; i++) {</span>
<span class="lineNum">     182 </span><span class="lineCov">       7374 :                 for (j=0; j&lt;K-1; j++) {</span>
<span class="lineNum">     183 </span><span class="lineCov">       5529 :                         value += pow(matrix_get(model-&gt;V, K-1, i, j), 2.0);</span>
<span class="lineNum">     184 </span>            :                 }
<span class="lineNum">     185 </span>            :         }
<span class="lineNum">     186 </span><span class="lineCov">        469 :         loss += model-&gt;lambda * value;</span>
<span class="lineNum">     187 </span>            : 
<span class="lineNum">     188 </span><span class="lineCov">        469 :         return loss;</span>
<span class="lineNum">     189 </span>            : }
<span class="lineNum">     190 </span>            : 
<span class="lineNum">     191 </span>            : /**
<span class="lineNum">     192 </span>            :  * @brief Use step doubling
<span class="lineNum">     193 </span>            :  *
<span class="lineNum">     194 </span>            :  * @details
<span class="lineNum">     195 </span>            :  * Step doubling can be used to speed up the maorization algorithm. Instead of
<span class="lineNum">     196 </span>            :  * using the value at the minimimum of the majorization function, the value
<span class="lineNum">     197 </span>            :  * ``opposite'' the majorization point is used. This can essentially cut the
<span class="lineNum">     198 </span>            :  * number of iterations necessary to reach the minimum in half.
<span class="lineNum">     199 </span>            :  *
<a name="200"><span class="lineNum">     200 </span>            :  * @param[in]   model   GenModel containing the augmented parameters</a>
<span class="lineNum">     201 </span>            :  */
<span class="lineNum">     202 </span><span class="lineCov">        312 : void gensvm_step_doubling(struct GenModel *model)</span>
<span class="lineNum">     203 </span>            : {
<span class="lineNum">     204 </span>            :         long i, j;
<span class="lineNum">     205 </span>            :         double value;
<span class="lineNum">     206 </span>            : 
<span class="lineNum">     207 </span><span class="lineCov">        312 :         long m = model-&gt;m;</span>
<span class="lineNum">     208 </span><span class="lineCov">        312 :         long K = model-&gt;K;</span>
<span class="lineNum">     209 </span>            : 
<span class="lineNum">     210 </span><span class="lineCov">       1842 :         for (i=0; i&lt;m+1; i++) {</span>
<span class="lineNum">     211 </span><span class="lineCov">       6116 :                 for (j=0; j&lt;K-1; j++) {</span>
<span class="lineNum">     212 </span><span class="lineCov">       4586 :                         matrix_mul(model-&gt;V, K-1, i, j, 2.0);</span>
<span class="lineNum">     213 </span><span class="lineCov">       4586 :                         value = - matrix_get(model-&gt;Vbar, K-1, i, j);</span>
<span class="lineNum">     214 </span><span class="lineCov">       4586 :                         matrix_add(model-&gt;V, K-1, i, j, value);</span>
<span class="lineNum">     215 </span>            :                 }
<span class="lineNum">     216 </span>            :         }
<span class="lineNum">     217 </span><span class="lineCov">        312 : }</span>
<span class="lineNum">     218 </span>            : 
<span class="lineNum">     219 </span>            : /**
<span class="lineNum">     220 </span>            :  * @brief Calculate the Huber hinge errors
<span class="lineNum">     221 </span>            :  *
<span class="lineNum">     222 </span>            :  * @details
<span class="lineNum">     223 </span>            :  * For each of the scalar errors in Q the Huber hinge errors are
<span class="lineNum">     224 </span>            :  * calculated. The Huber hinge is here defined as
<span class="lineNum">     225 </span>            :  * @f[
<span class="lineNum">     226 </span>            :  *      h(q) =
<span class="lineNum">     227 </span>            :  *              \begin{dcases}
<span class="lineNum">     228 </span>            :  *                      1 - q - \frac{\kappa + 1}{2} &amp; \text{if } q \leq
<span class="lineNum">     229 </span>            :  *                      -\kappa \\
<span class="lineNum">     230 </span>            :  *                      \frac{1}{2(\kappa + 1)} ( 1 - q)^2 &amp; \text{if } q \in
<span class="lineNum">     231 </span>            :  *                      (-\kappa, 1] \\
<span class="lineNum">     232 </span>            :  *                      0 &amp; \text{if } q &gt; 1
<span class="lineNum">     233 </span>            :  *              \end{dcases}
<span class="lineNum">     234 </span>            :  * @f]
<span class="lineNum">     235 </span>            :  *
<a name="236"><span class="lineNum">     236 </span>            :  * @param[in,out] model         the corresponding GenModel</a>
<span class="lineNum">     237 </span>            :  */
<span class="lineNum">     238 </span><span class="lineCov">        472 : void gensvm_calculate_huber(struct GenModel *model)</span>
<span class="lineNum">     239 </span>            : {
<span class="lineNum">     240 </span>            :         long i, j;
<span class="lineNum">     241 </span>            :         double q, value;
<span class="lineNum">     242 </span>            : 
<span class="lineNum">     243 </span><span class="lineCov">       4913 :         for (i=0; i&lt;model-&gt;n; i++) {</span>
<span class="lineNum">     244 </span><span class="lineCov">      22168 :                 for (j=0; j&lt;model-&gt;K; j++) {</span>
<span class="lineNum">     245 </span><span class="lineCov">      17727 :                         q = matrix_get(model-&gt;Q, model-&gt;K, i, j);</span>
<span class="lineNum">     246 </span><span class="lineCov">      17727 :                         value = 0.0;</span>
<span class="lineNum">     247 </span><span class="lineCov">      17727 :                         if (q &lt;= -model-&gt;kappa) {</span>
<span class="lineNum">     248 </span><span class="lineCov">         59 :                                 value = 1.0 - q - (model-&gt;kappa+1.0)/2.0;</span>
<span class="lineNum">     249 </span><span class="lineCov">      17668 :                         } else if (q &lt;= 1.0) {</span>
<span class="lineNum">     250 </span><span class="lineCov">      15361 :                                 value = 1.0/(2.0*model-&gt;kappa+2.0)*pow(1.0 - q,</span>
<span class="lineNum">     251 </span>            :                                                 2.0);
<span class="lineNum">     252 </span>            :                         }
<span class="lineNum">     253 </span><span class="lineCov">      17727 :                         matrix_set(model-&gt;H, model-&gt;K, i, j, value);</span>
<span class="lineNum">     254 </span>            :                 }
<span class="lineNum">     255 </span>            :         }
<span class="lineNum">     256 </span><span class="lineCov">        472 : }</span>
<span class="lineNum">     257 </span>            : 
<span class="lineNum">     258 </span>            : /**
<span class="lineNum">     259 </span>            :  * @brief Calculate the scalar errors
<span class="lineNum">     260 </span>            :  *
<span class="lineNum">     261 </span>            :  * @details
<span class="lineNum">     262 </span>            :  * Calculate the scalar errors q based on the current estimate of V, and
<span class="lineNum">     263 </span>            :  * store these in Q. It is assumed that the memory for Q has already been
<span class="lineNum">     264 </span>            :  * allocated. In addition, the matrix ZV is calculated here. It is assigned
<span class="lineNum">     265 </span>            :  * to a pre-allocated block of memory, which is passed to this function.
<span class="lineNum">     266 </span>            :  *
<span class="lineNum">     267 </span>            :  * @param[in,out]       model   the corresponding GenModel
<span class="lineNum">     268 </span>            :  * @param[in]           data    the corresponding GenData
<span class="lineNum">     269 </span>            :  * @param[in,out]       ZV      a pointer to a memory block for ZV. On exit
<span class="lineNum">     270 </span>            :  *                              this block is updated with the new ZV matrix
<a name="271"><span class="lineNum">     271 </span>            :  *                              calculated with GenModel::V</a>
<span class="lineNum">     272 </span>            :  */
<span class="lineNum">     273 </span><span class="lineCov">        472 : void gensvm_calculate_errors(struct GenModel *model, struct GenData *data,</span>
<span class="lineNum">     274 </span>            :                 double *ZV)
<span class="lineNum">     275 </span>            : {
<span class="lineNum">     276 </span>            :         long i, j;
<span class="lineNum">     277 </span><span class="lineCov">        472 :         double q, *uu_row = NULL;</span>
<span class="lineNum">     278 </span>            : 
<span class="lineNum">     279 </span><span class="lineCov">        472 :         long n = model-&gt;n;</span>
<span class="lineNum">     280 </span><span class="lineCov">        472 :         long K = model-&gt;K;</span>
<span class="lineNum">     281 </span>            : 
<span class="lineNum">     282 </span><span class="lineCov">        472 :         gensvm_calculate_ZV(model, data, ZV);</span>
<span class="lineNum">     283 </span>            : 
<span class="lineNum">     284 </span><span class="lineCov">       4916 :         for (i=0; i&lt;n; i++) {</span>
<span class="lineNum">     285 </span><span class="lineCov">      22180 :                 for (j=0; j&lt;K; j++) {</span>
<span class="lineNum">     286 </span><span class="lineCov">      17736 :                         if (j == (data-&gt;y[i]-1))</span>
<span class="lineNum">     287 </span><span class="lineCov">       4444 :                                 continue;</span>
<span class="lineNum">     288 </span><span class="lineCov">      13292 :                         uu_row = &amp;model-&gt;UU[((data-&gt;y[i]-1)*K+j)*(K-1)];</span>
<span class="lineNum">     289 </span><span class="lineCov">      13292 :                         q = cblas_ddot(K-1, &amp;ZV[i*(K-1)], 1, uu_row, 1);</span>
<span class="lineNum">     290 </span><span class="lineCov">      13292 :                         matrix_set(model-&gt;Q, K, i, j, q);</span>
<span class="lineNum">     291 </span>            :                 }
<span class="lineNum">     292 </span>            :         }
<span class="lineNum">     293 </span><span class="lineCov">        472 : }</span>
<span class="lineNum">     294 </span>            : 
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.12</a></td></tr>
  </table>
  <br>

</body>
</html>
