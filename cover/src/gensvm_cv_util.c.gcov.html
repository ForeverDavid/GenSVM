<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - coverage.all - src/gensvm_cv_util.c</title>
  <link rel="stylesheet" type="text/css" href="../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../index.html">top level</a> - <a href="index.html">src</a> - gensvm_cv_util.c<span style="font-size: 80%;"> (source / <a href="gensvm_cv_util.c.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">coverage.all</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">127</td>
            <td class="headerCovTableEntry">127</td>
            <td class="headerCovTableEntryHi">100.0 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2017-02-17 19:16:12</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">4</td>
            <td class="headerCovTableEntry">4</td>
            <td class="headerCovTableEntryHi">100.0 %</td>
          </tr>
          <tr><td><img src="../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : /**</a>
<span class="lineNum">       2 </span>            :  * @file gensvm_cv_util.c
<span class="lineNum">       3 </span>            :  * @author G.J.J. van den Burg
<span class="lineNum">       4 </span>            :  * @date 2014-01-07
<span class="lineNum">       5 </span>            :  * @brief Functions for cross validation
<span class="lineNum">       6 </span>            :  *
<span class="lineNum">       7 </span>            :  * @details
<span class="lineNum">       8 </span>            :  * This file contains functions for performing cross validation. The funtion
<span class="lineNum">       9 </span>            :  * gensvm_make_cv_split() creates a cross validation vector for non-stratified
<span class="lineNum">      10 </span>            :  * cross validation. The function gensvm_get_tt_split() creates a train and
<span class="lineNum">      11 </span>            :  * test dataset from a given dataset and a pre-determined CV partition vector.
<span class="lineNum">      12 </span>            :  * See individual function documentation for details.
<span class="lineNum">      13 </span>            :  *
<span class="lineNum">      14 </span>            :  * @copyright
<span class="lineNum">      15 </span>            :  Copyright 2016, G.J.J. van den Burg.
<span class="lineNum">      16 </span>            : 
<span class="lineNum">      17 </span>            :  This file is part of GenSVM.
<span class="lineNum">      18 </span>            : 
<span class="lineNum">      19 </span>            :  GenSVM is free software: you can redistribute it and/or modify
<span class="lineNum">      20 </span>            :  it under the terms of the GNU General Public License as published by
<span class="lineNum">      21 </span>            :  the Free Software Foundation, either version 3 of the License, or
<span class="lineNum">      22 </span>            :  (at your option) any later version.
<span class="lineNum">      23 </span>            : 
<span class="lineNum">      24 </span>            :  GenSVM is distributed in the hope that it will be useful,
<span class="lineNum">      25 </span>            :  but WITHOUT ANY WARRANTY; without even the implied warranty of
<span class="lineNum">      26 </span>            :  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
<span class="lineNum">      27 </span>            :  GNU General Public License for more details.
<span class="lineNum">      28 </span>            : 
<span class="lineNum">      29 </span>            :  You should have received a copy of the GNU General Public License
<span class="lineNum">      30 </span>            :  along with GenSVM. If not, see &lt;http://www.gnu.org/licenses/&gt;.
<span class="lineNum">      31 </span>            : 
<span class="lineNum">      32 </span>            :  */
<span class="lineNum">      33 </span>            : 
<span class="lineNum">      34 </span>            : #include &quot;gensvm_cv_util.h&quot;
<span class="lineNum">      35 </span>            : 
<span class="lineNum">      36 </span>            : /**
<span class="lineNum">      37 </span>            :  * @brief Create a cross validation split vector
<span class="lineNum">      38 </span>            :  *
<span class="lineNum">      39 </span>            :  * @details
<span class="lineNum">      40 </span>            :  * A pre-allocated vector of length N is created which can be used to define
<span class="lineNum">      41 </span>            :  * cross validation splits. The folds are contain between
<span class="lineNum">      42 </span>            :  * @f$ \lfloor N / folds \rfloor @f$ and @f$ \lceil N / folds \rceil @f$
<span class="lineNum">      43 </span>            :  * instances. An instance is mapped to a partition randomly until all folds
<span class="lineNum">      44 </span>            :  * contain @f$ N \% folds @f$ instances. The zero fold then contains
<span class="lineNum">      45 </span>            :  * @f$ N / folds + N \% folds @f$ instances. These remaining @f$ N \% folds @f$
<span class="lineNum">      46 </span>            :  * instances are then distributed over the first @f$ N \% folds @f$ folds.
<span class="lineNum">      47 </span>            :  *
<span class="lineNum">      48 </span>            :  * @param[in]           N       number of instances
<span class="lineNum">      49 </span>            :  * @param[in]           folds   number of folds
<span class="lineNum">      50 </span>            :  * @param[in,out]       cv_idx  array of size N which contains the fold index
<span class="lineNum">      51 </span>            :  *                              for each observation on exit
<a name="52"><span class="lineNum">      52 </span>            :  *</a>
<span class="lineNum">      53 </span>            :  */
<span class="lineNum">      54 </span><span class="lineCov">          2 : void gensvm_make_cv_split(long N, long folds, long *cv_idx)</span>
<span class="lineNum">      55 </span>            : {
<span class="lineNum">      56 </span>            :         long i, j, idx;
<span class="lineNum">      57 </span>            : 
<span class="lineNum">      58 </span><span class="lineCov">        113 :         for (i=0; i&lt;N; i++)</span>
<span class="lineNum">      59 </span><span class="lineCov">        111 :                 cv_idx[i] = 0;</span>
<span class="lineNum">      60 </span>            : 
<span class="lineNum">      61 </span><span class="lineCov">          2 :         long big_folds = N%folds;</span>
<span class="lineNum">      62 </span><span class="lineCov">          2 :         long small_fold_size = N/folds;</span>
<span class="lineNum">      63 </span>            : 
<span class="lineNum">      64 </span><span class="lineCov">          2 :         j = 0;</span>
<span class="lineNum">      65 </span><span class="lineCov">        108 :         for (i=0; i&lt;small_fold_size*folds; i++)</span>
<span class="lineNum">      66 </span>            :                 while (1) {
<span class="lineNum">      67 </span><span class="lineCov">        406 :                         idx = rand()%N;</span>
<span class="lineNum">      68 </span><span class="lineCov">        256 :                         if (cv_idx[idx] == 0) {</span>
<span class="lineNum">      69 </span><span class="lineCov">        106 :                                 cv_idx[idx] = j;</span>
<span class="lineNum">      70 </span><span class="lineCov">        106 :                                 j++;</span>
<span class="lineNum">      71 </span><span class="lineCov">        106 :                                 j%=folds;</span>
<span class="lineNum">      72 </span><span class="lineCov">        106 :                                 break;</span>
<span class="lineNum">      73 </span>            :                         }
<span class="lineNum">      74 </span>            :                 }
<span class="lineNum">      75 </span><span class="lineCov">          2 :         j = 0;</span>
<span class="lineNum">      76 </span><span class="lineCov">          2 :         i = 0;</span>
<span class="lineNum">      77 </span><span class="lineCov">         18 :         while (i &lt; big_folds) {</span>
<span class="lineNum">      78 </span><span class="lineCov">         14 :                 if (cv_idx[j] == 0) {</span>
<span class="lineNum">      79 </span><span class="lineCov">          5 :                         cv_idx[j] = i++;</span>
<span class="lineNum">      80 </span>            :                 }
<span class="lineNum">      81 </span><span class="lineCov">         14 :                 j++;</span>
<span class="lineNum">      82 </span>            :         }
<span class="lineNum">      83 </span><span class="lineCov">          2 : }</span>
<span class="lineNum">      84 </span>            : 
<span class="lineNum">      85 </span>            : /**
<span class="lineNum">      86 </span>            :  * @brief Wrapper around sparse/dense versions of this function
<span class="lineNum">      87 </span>            :  *
<span class="lineNum">      88 </span>            :  * @details
<span class="lineNum">      89 </span>            :  * This function tests if the data in the full_data structure is stored in a
<span class="lineNum">      90 </span>            :  * dense matrix format or not, and calls gensvm_get_tt_split_dense() or
<span class="lineNum">      91 </span>            :  * gensvm_get_tt_split_sparse() accordingly.
<span class="lineNum">      92 </span>            :  *
<span class="lineNum">      93 </span>            :  * @sa
<span class="lineNum">      94 </span>            :  * gensvm_get_tt_split_dense(), gensvm_get_tt_split_sparse()
<span class="lineNum">      95 </span>            :  *
<span class="lineNum">      96 </span>            :  * @param[in]           full_data       a GenData structure for the entire
<span class="lineNum">      97 </span>            :  *                                      dataset
<span class="lineNum">      98 </span>            :  * @param[in,out]       train_data      an initialized GenData structure which
<span class="lineNum">      99 </span>            :  *                                      on exit contains the training dataset
<span class="lineNum">     100 </span>            :  * @param[in,out]       test_data       an initialized GenData structure which
<span class="lineNum">     101 </span>            :  *                                      on exit contains the test dataset
<span class="lineNum">     102 </span>            :  * @param[in]           cv_idx          a vector of cv partitions created by
<span class="lineNum">     103 </span>            :  *                                      gensvm_make_cv_split()
<span class="lineNum">     104 </span>            :  * @param[in]           fold_idx        index of the fold which becomes the
<a name="105"><span class="lineNum">     105 </span>            :  *                                      test dataset</a>
<span class="lineNum">     106 </span>            :  */
<span class="lineNum">     107 </span><span class="lineCov">          2 : void gensvm_get_tt_split(struct GenData *full_data,</span>
<span class="lineNum">     108 </span>            :                 struct GenData *train_data, struct GenData *test_data,
<span class="lineNum">     109 </span>            :                 long *cv_idx, long fold_idx)
<span class="lineNum">     110 </span>            : {
<span class="lineNum">     111 </span><span class="lineCov">          2 :         if (full_data-&gt;Z == NULL)</span>
<span class="lineNum">     112 </span><span class="lineCov">          1 :                 gensvm_get_tt_split_sparse(full_data, train_data, test_data,</span>
<span class="lineNum">     113 </span>            :                                 cv_idx, fold_idx);
<span class="lineNum">     114 </span>            :         else
<span class="lineNum">     115 </span><span class="lineCov">          1 :                 gensvm_get_tt_split_dense(full_data, train_data, test_data,</span>
<span class="lineNum">     116 </span>            :                                 cv_idx, fold_idx);
<span class="lineNum">     117 </span><span class="lineCov">          2 : }</span>
<span class="lineNum">     118 </span>            : 
<span class="lineNum">     119 </span>            : /**
<span class="lineNum">     120 </span>            :  * @brief Create train and test datasets for a CV split with dense data
<span class="lineNum">     121 </span>            :  *
<span class="lineNum">     122 </span>            :  * @details
<span class="lineNum">     123 </span>            :  * Given a GenData structure for the full dataset, a previously created
<span class="lineNum">     124 </span>            :  * cross validation split vector and a fold index, a training and test dataset
<span class="lineNum">     125 </span>            :  * are created. It is assumed here that the data is stored as a dense matrix,
<span class="lineNum">     126 </span>            :  * and that the train and test data should also be stored as a dense matrix.
<span class="lineNum">     127 </span>            :  *
<span class="lineNum">     128 </span>            :  * @sa
<span class="lineNum">     129 </span>            :  * gensvm_get_tt_split_sparse(), gensvm_get_tt_split()
<span class="lineNum">     130 </span>            :  *
<span class="lineNum">     131 </span>            :  * @param[in]           full_data       a GenData structure for the entire
<span class="lineNum">     132 </span>            :  *                                      dataset
<span class="lineNum">     133 </span>            :  * @param[in,out]       train_data      an initialized GenData structure which
<span class="lineNum">     134 </span>            :  *                                      on exit contains the training dataset
<span class="lineNum">     135 </span>            :  * @param[in,out]       test_data       an initialized GenData structure which
<span class="lineNum">     136 </span>            :  *                                      on exit contains the test dataset
<span class="lineNum">     137 </span>            :  * @param[in]           cv_idx          a vector of cv partitions created by
<span class="lineNum">     138 </span>            :  *                                      gensvm_make_cv_split()
<span class="lineNum">     139 </span>            :  * @param[in]           fold_idx        index of the fold which becomes the
<a name="140"><span class="lineNum">     140 </span>            :  *                                      test dataset</a>
<span class="lineNum">     141 </span>            :  */
<span class="lineNum">     142 </span><span class="lineCov">          1 : void gensvm_get_tt_split_dense(struct GenData *full_data,</span>
<span class="lineNum">     143 </span>            :                 struct GenData *train_data, struct GenData *test_data,
<span class="lineNum">     144 </span>            :                 long *cv_idx, long fold_idx)
<span class="lineNum">     145 </span>            : {
<span class="lineNum">     146 </span>            :         long i, j, k, l, test_n, train_n;
<span class="lineNum">     147 </span>            : 
<span class="lineNum">     148 </span><span class="lineCov">          1 :         long n = full_data-&gt;n;</span>
<span class="lineNum">     149 </span><span class="lineCov">          1 :         long m = full_data-&gt;m;</span>
<span class="lineNum">     150 </span><span class="lineCov">          1 :         long K = full_data-&gt;K;</span>
<span class="lineNum">     151 </span>            : 
<span class="lineNum">     152 </span>            :         double value;
<span class="lineNum">     153 </span>            : 
<span class="lineNum">     154 </span><span class="lineCov">          1 :         test_n = 0;</span>
<span class="lineNum">     155 </span><span class="lineCov">         11 :         for (i=0; i&lt;n; i++)</span>
<span class="lineNum">     156 </span><span class="lineCov">         10 :                 if (cv_idx[i] == fold_idx)</span>
<span class="lineNum">     157 </span><span class="lineCov">          2 :                         test_n++;</span>
<span class="lineNum">     158 </span><span class="lineCov">          1 :         train_n = n - test_n;</span>
<span class="lineNum">     159 </span>            : 
<span class="lineNum">     160 </span><span class="lineCov">          1 :         test_data-&gt;n = test_n;</span>
<span class="lineNum">     161 </span><span class="lineCov">          1 :         train_data-&gt;n = train_n;</span>
<span class="lineNum">     162 </span>            : 
<span class="lineNum">     163 </span><span class="lineCov">          1 :         train_data-&gt;K = K;</span>
<span class="lineNum">     164 </span><span class="lineCov">          1 :         test_data-&gt;K = K;</span>
<span class="lineNum">     165 </span>            : 
<span class="lineNum">     166 </span><span class="lineCov">          1 :         train_data-&gt;m = m;</span>
<span class="lineNum">     167 </span><span class="lineCov">          1 :         test_data-&gt;m = m;</span>
<span class="lineNum">     168 </span>            : 
<span class="lineNum">     169 </span><span class="lineCov">          1 :         train_data-&gt;y = Calloc(long, train_n);</span>
<span class="lineNum">     170 </span><span class="lineCov">          1 :         test_data-&gt;y = Calloc(long, test_n);</span>
<span class="lineNum">     171 </span>            : 
<span class="lineNum">     172 </span><span class="lineCov">          1 :         train_data-&gt;RAW = Calloc(double, train_n*(m+1));</span>
<span class="lineNum">     173 </span><span class="lineCov">          1 :         test_data-&gt;RAW = Calloc(double, test_n*(m+1));</span>
<span class="lineNum">     174 </span>            : 
<span class="lineNum">     175 </span><span class="lineCov">          1 :         k = 0;</span>
<span class="lineNum">     176 </span><span class="lineCov">          1 :         l = 0;</span>
<span class="lineNum">     177 </span><span class="lineCov">         11 :         for (i=0; i&lt;n; i++) {</span>
<span class="lineNum">     178 </span><span class="lineCov">         10 :                 if (cv_idx[i] == fold_idx) {</span>
<span class="lineNum">     179 </span><span class="lineCov">          2 :                         test_data-&gt;y[k] = full_data-&gt;y[i];</span>
<span class="lineNum">     180 </span><span class="lineCov">          8 :                         for (j=0; j&lt;m+1; j++) {</span>
<span class="lineNum">     181 </span><span class="lineCov">          6 :                                 value = matrix_get(full_data-&gt;RAW, m+1, i, j);</span>
<span class="lineNum">     182 </span><span class="lineCov">          6 :                                 matrix_set(test_data-&gt;RAW, m+1, k, j, value);</span>
<span class="lineNum">     183 </span>            :                         }
<span class="lineNum">     184 </span><span class="lineCov">          2 :                         k++;</span>
<span class="lineNum">     185 </span>            :                 } else {
<span class="lineNum">     186 </span><span class="lineCov">          8 :                         train_data-&gt;y[l] = full_data-&gt;y[i];</span>
<span class="lineNum">     187 </span><span class="lineCov">         32 :                         for (j=0; j&lt;m+1; j++) {</span>
<span class="lineNum">     188 </span><span class="lineCov">         24 :                                 value = matrix_get(full_data-&gt;RAW, m+1, i, j);</span>
<span class="lineNum">     189 </span><span class="lineCov">         24 :                                 matrix_set(train_data-&gt;RAW, m+1, l, j, value);</span>
<span class="lineNum">     190 </span>            :                         }
<span class="lineNum">     191 </span><span class="lineCov">          8 :                         l++;</span>
<span class="lineNum">     192 </span>            :                 }
<span class="lineNum">     193 </span>            :         }
<span class="lineNum">     194 </span>            : 
<span class="lineNum">     195 </span><span class="lineCov">          1 :         train_data-&gt;Z = train_data-&gt;RAW;</span>
<span class="lineNum">     196 </span><span class="lineCov">          1 :         test_data-&gt;Z = test_data-&gt;RAW;</span>
<span class="lineNum">     197 </span><span class="lineCov">          1 : }</span>
<span class="lineNum">     198 </span>            : 
<span class="lineNum">     199 </span>            : 
<span class="lineNum">     200 </span>            : /**
<span class="lineNum">     201 </span>            :  * @brief Create train and test dataset for a CV split with sparse data
<span class="lineNum">     202 </span>            :  *
<span class="lineNum">     203 </span>            :  * @details
<span class="lineNum">     204 </span>            :  * Given a GenData structure for the full dataset, a previously created
<span class="lineNum">     205 </span>            :  * cross validation split vector and a fold index, a training and test dataset
<span class="lineNum">     206 </span>            :  * are created. It is assumed here that the data is stored as a sparse matrix,
<span class="lineNum">     207 </span>            :  * and that the train and test data should also be stored as a sparse matrix.
<span class="lineNum">     208 </span>            :  *
<span class="lineNum">     209 </span>            :  * @sa
<span class="lineNum">     210 </span>            :  * gensvm_get_tt_split_dense(), gensvm_get_tt_split()
<span class="lineNum">     211 </span>            :  *
<span class="lineNum">     212 </span>            :  * @param[in]           full_data       a GenData structure for the entire
<span class="lineNum">     213 </span>            :  *                                      dataset
<span class="lineNum">     214 </span>            :  * @param[in,out]       train_data      an initialized GenData structure which
<span class="lineNum">     215 </span>            :  *                                      on exit contains the training dataset
<span class="lineNum">     216 </span>            :  * @param[in,out]       test_data       an initialized GenData structure which
<span class="lineNum">     217 </span>            :  *                                      on exit contains the test dataset
<span class="lineNum">     218 </span>            :  * @param[in]           cv_idx          a vector of cv partitions created by
<span class="lineNum">     219 </span>            :  *                                      gensvm_make_cv_split()
<span class="lineNum">     220 </span>            :  * @param[in]           fold_idx        index of the fold which becomes the
<a name="221"><span class="lineNum">     221 </span>            :  *                                      test dataset</a>
<span class="lineNum">     222 </span>            :  */
<span class="lineNum">     223 </span><span class="lineCov">          1 : void gensvm_get_tt_split_sparse(struct GenData *full_data,</span>
<span class="lineNum">     224 </span>            :                 struct GenData *train_data, struct GenData *test_data,
<span class="lineNum">     225 </span>            :                 long *cv_idx, long fold_idx)
<span class="lineNum">     226 </span>            : {
<span class="lineNum">     227 </span>            :         long i, j, test_n, train_n, train_nnz, test_nnz, row_nnz, jj,
<span class="lineNum">     228 </span>            :              jj_start, jj_end,
<span class="lineNum">     229 </span><span class="lineCov">          1 :              tr_nnz_idx = 0,</span>
<span class="lineNum">     230 </span><span class="lineCov">          1 :              tr_row_idx = 0,</span>
<span class="lineNum">     231 </span><span class="lineCov">          1 :              te_nnz_idx = 0,</span>
<span class="lineNum">     232 </span><span class="lineCov">          1 :              te_row_idx = 0;</span>
<span class="lineNum">     233 </span>            : 
<span class="lineNum">     234 </span>            :         double value;
<span class="lineNum">     235 </span>            : 
<span class="lineNum">     236 </span>            :         // determine number of instances in test and train
<span class="lineNum">     237 </span><span class="lineCov">          1 :         test_n = 0;</span>
<span class="lineNum">     238 </span><span class="lineCov">         11 :         for (i=0; i&lt;full_data-&gt;n; i++)</span>
<span class="lineNum">     239 </span><span class="lineCov">         10 :                 if (cv_idx[i] == fold_idx)</span>
<span class="lineNum">     240 </span><span class="lineCov">          2 :                         test_n++;</span>
<span class="lineNum">     241 </span><span class="lineCov">          1 :         train_n = full_data-&gt;n - test_n;</span>
<span class="lineNum">     242 </span>            : 
<span class="lineNum">     243 </span>            :         // set n, m, K variables
<span class="lineNum">     244 </span><span class="lineCov">          1 :         train_data-&gt;n = train_n;</span>
<span class="lineNum">     245 </span><span class="lineCov">          1 :         train_data-&gt;m = full_data-&gt;m;</span>
<span class="lineNum">     246 </span><span class="lineCov">          1 :         train_data-&gt;K = full_data-&gt;K;</span>
<span class="lineNum">     247 </span><span class="lineCov">          1 :         test_data-&gt;n = test_n;</span>
<span class="lineNum">     248 </span><span class="lineCov">          1 :         test_data-&gt;m = full_data-&gt;m;</span>
<span class="lineNum">     249 </span><span class="lineCov">          1 :         test_data-&gt;K = full_data-&gt;K;</span>
<span class="lineNum">     250 </span>            : 
<span class="lineNum">     251 </span>            :         // allocate outcome
<span class="lineNum">     252 </span><span class="lineCov">          1 :         train_data-&gt;y = Calloc(long, train_n);</span>
<span class="lineNum">     253 </span><span class="lineCov">          1 :         test_data-&gt;y = Calloc(long, test_n);</span>
<span class="lineNum">     254 </span>            : 
<span class="lineNum">     255 </span>            :         // compute train nnz and test nnz
<span class="lineNum">     256 </span><span class="lineCov">          1 :         train_nnz = 0;</span>
<span class="lineNum">     257 </span><span class="lineCov">          1 :         test_nnz = 0;</span>
<span class="lineNum">     258 </span><span class="lineCov">         11 :         for (i=0; i&lt;full_data-&gt;n; i++) {</span>
<span class="lineNum">     259 </span><span class="lineCov">         10 :                 row_nnz = full_data-&gt;spZ-&gt;ia[i+1] - full_data-&gt;spZ-&gt;ia[i];</span>
<span class="lineNum">     260 </span><span class="lineCov">         10 :                 if (cv_idx[i] == fold_idx) {</span>
<span class="lineNum">     261 </span><span class="lineCov">          2 :                         test_nnz += row_nnz;</span>
<span class="lineNum">     262 </span>            :                 } else {
<span class="lineNum">     263 </span><span class="lineCov">          8 :                         train_nnz += row_nnz;</span>
<span class="lineNum">     264 </span>            :                 }
<span class="lineNum">     265 </span>            :         }
<span class="lineNum">     266 </span>            : 
<span class="lineNum">     267 </span>            :         // allocate the train GenSparse
<span class="lineNum">     268 </span><span class="lineCov">          1 :         train_data-&gt;spZ = gensvm_init_sparse();</span>
<span class="lineNum">     269 </span><span class="lineCov">          1 :         test_data-&gt;spZ = gensvm_init_sparse();</span>
<span class="lineNum">     270 </span>            : 
<span class="lineNum">     271 </span>            :         // set GenSparse variables for train
<span class="lineNum">     272 </span><span class="lineCov">          1 :         train_data-&gt;spZ-&gt;nnz = train_nnz;</span>
<span class="lineNum">     273 </span><span class="lineCov">          1 :         train_data-&gt;spZ-&gt;n_row = train_n;</span>
<span class="lineNum">     274 </span><span class="lineCov">          1 :         train_data-&gt;spZ-&gt;n_col = full_data-&gt;m+1;</span>
<span class="lineNum">     275 </span><span class="lineCov">          1 :         train_data-&gt;spZ-&gt;values = Calloc(double, train_nnz);</span>
<span class="lineNum">     276 </span><span class="lineCov">          1 :         train_data-&gt;spZ-&gt;ia = Calloc(long, train_n+1);</span>
<span class="lineNum">     277 </span><span class="lineCov">          1 :         train_data-&gt;spZ-&gt;ja = Calloc(long, train_nnz);</span>
<span class="lineNum">     278 </span>            : 
<span class="lineNum">     279 </span>            :         // set GenSparse variables for test
<span class="lineNum">     280 </span><span class="lineCov">          1 :         test_data-&gt;spZ-&gt;nnz = test_nnz;</span>
<span class="lineNum">     281 </span><span class="lineCov">          1 :         test_data-&gt;spZ-&gt;n_row = test_n;</span>
<span class="lineNum">     282 </span><span class="lineCov">          1 :         test_data-&gt;spZ-&gt;n_col = full_data-&gt;m+1;</span>
<span class="lineNum">     283 </span><span class="lineCov">          1 :         test_data-&gt;spZ-&gt;values = Calloc(double, test_nnz);</span>
<span class="lineNum">     284 </span><span class="lineCov">          1 :         test_data-&gt;spZ-&gt;ia = Calloc(long, test_n+1);</span>
<span class="lineNum">     285 </span><span class="lineCov">          1 :         test_data-&gt;spZ-&gt;ja = Calloc(long, test_nnz);</span>
<span class="lineNum">     286 </span>            : 
<span class="lineNum">     287 </span><span class="lineCov">          1 :         tr_nnz_idx = 0;</span>
<span class="lineNum">     288 </span><span class="lineCov">          1 :         tr_row_idx = 0;</span>
<span class="lineNum">     289 </span><span class="lineCov">          1 :         te_nnz_idx = 0;</span>
<span class="lineNum">     290 </span><span class="lineCov">          1 :         te_row_idx = 0;</span>
<span class="lineNum">     291 </span>            : 
<span class="lineNum">     292 </span><span class="lineCov">          1 :         test_data-&gt;spZ-&gt;ia[0] = 0;</span>
<span class="lineNum">     293 </span><span class="lineCov">          1 :         train_data-&gt;spZ-&gt;ia[0] = 0;</span>
<span class="lineNum">     294 </span><span class="lineCov">         11 :         for (i=0; i&lt;full_data-&gt;n; i++) {</span>
<span class="lineNum">     295 </span><span class="lineCov">         10 :                 jj_start = full_data-&gt;spZ-&gt;ia[i];</span>
<span class="lineNum">     296 </span><span class="lineCov">         10 :                 jj_end = full_data-&gt;spZ-&gt;ia[i+1];</span>
<span class="lineNum">     297 </span>            : 
<span class="lineNum">     298 </span><span class="lineCov">         30 :                 for (jj=jj_start; jj&lt;jj_end; jj++) {</span>
<span class="lineNum">     299 </span><span class="lineCov">         20 :                         j = full_data-&gt;spZ-&gt;ja[jj];</span>
<span class="lineNum">     300 </span><span class="lineCov">         20 :                         value = full_data-&gt;spZ-&gt;values[jj];</span>
<span class="lineNum">     301 </span>            : 
<span class="lineNum">     302 </span><span class="lineCov">         20 :                         if (cv_idx[i] == fold_idx) {</span>
<span class="lineNum">     303 </span><span class="lineCov">          4 :                                 test_data-&gt;spZ-&gt;values[te_nnz_idx] = value;</span>
<span class="lineNum">     304 </span><span class="lineCov">          4 :                                 test_data-&gt;spZ-&gt;ja[te_nnz_idx] = j;</span>
<span class="lineNum">     305 </span><span class="lineCov">          4 :                                 te_nnz_idx++;</span>
<span class="lineNum">     306 </span>            :                         } else {
<span class="lineNum">     307 </span><span class="lineCov">         16 :                                 train_data-&gt;spZ-&gt;values[tr_nnz_idx] = value;</span>
<span class="lineNum">     308 </span><span class="lineCov">         16 :                                 train_data-&gt;spZ-&gt;ja[tr_nnz_idx] = j;</span>
<span class="lineNum">     309 </span><span class="lineCov">         16 :                                 tr_nnz_idx++;</span>
<span class="lineNum">     310 </span>            :                         }
<span class="lineNum">     311 </span>            :                 }
<span class="lineNum">     312 </span>            : 
<span class="lineNum">     313 </span><span class="lineCov">         10 :                 if (cv_idx[i] == fold_idx) {</span>
<span class="lineNum">     314 </span><span class="lineCov">          2 :                         test_data-&gt;y[te_row_idx] = full_data-&gt;y[i];</span>
<span class="lineNum">     315 </span><span class="lineCov">          2 :                         test_data-&gt;spZ-&gt;ia[te_row_idx+1] = te_nnz_idx;</span>
<span class="lineNum">     316 </span><span class="lineCov">          2 :                         te_row_idx++;</span>
<span class="lineNum">     317 </span>            :                 } else {
<span class="lineNum">     318 </span><span class="lineCov">          8 :                         train_data-&gt;y[tr_row_idx] = full_data-&gt;y[i];</span>
<span class="lineNum">     319 </span><span class="lineCov">          8 :                         train_data-&gt;spZ-&gt;ia[tr_row_idx+1] = tr_nnz_idx;</span>
<span class="lineNum">     320 </span><span class="lineCov">          8 :                         tr_row_idx++;</span>
<span class="lineNum">     321 </span>            :                 }
<span class="lineNum">     322 </span>            :         }
<span class="lineNum">     323 </span><span class="lineCov">          1 : }</span>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.12</a></td></tr>
  </table>
  <br>

</body>
</html>
